{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Completion System\n",
    "\n",
    "This is a JavaScript Code Prediction Systemï¼ˆwith Huge dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token = utils.load_dict_parameter(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UnaryExpression=$$=True=$$=True\n",
      "1 UpdateExpression=$$=True=$$=True\n",
      "2 TryStatement=$$=False=$$=False\n",
      "3 ConditionalExpression=$$=False=$$=True\n",
      "4 CallExpression=$$=True=$$=True\n",
      "5 SequenceExpression=$$=True=$$=False\n",
      "6 AssignmentExpression=$$=False=$$=False\n",
      "7 ConditionalExpression=$$=False=$$=False\n",
      "8 AssignmentExpression=$$=False=$$=True\n",
      "9 ExpressionStatement=$$=True=$$=False\n",
      "10 ForInStatement=$$=False=$$=True\n",
      "11 Property=$$=False=$$=True\n",
      "12 AssignmentExpression=$$=True=$$=False\n",
      "13 ForInStatement=$$=True=$$=True\n",
      "14 ArrayExpression=$$=True=$$=True\n",
      "15 SequenceExpression=$$=True=$$=True\n",
      "16 ConditionalExpression=$$=True=$$=True\n",
      "17 ArrayAccess=$$=False=$$=True\n",
      "18 LogicalExpression=$$=True=$$=True\n",
      "19 NewExpression=$$=False=$$=True\n",
      "20 ArrayAccess=$$=False=$$=False\n",
      "21 UpdateExpression=$$=True=$$=False\n",
      "22 VariableDeclarator=$$=True=$$=True\n",
      "23 FunctionDeclaration=$$=False=$$=False\n",
      "24 AssignmentExpression=$$=True=$$=True\n",
      "25 ExpressionStatement=$$=False=$$=True\n",
      "26 FunctionExpression=$$=True=$$=True\n",
      "27 TryStatement=$$=False=$$=True\n",
      "28 BlockStatement=$$=False=$$=False\n",
      "29 UnaryExpression=$$=False=$$=True\n",
      "30 ReturnStatement=$$=False=$$=False\n",
      "31 UpdateExpression=$$=False=$$=False\n",
      "32 IfStatement=$$=True=$$=False\n",
      "33 UpdateExpression=$$=False=$$=True\n",
      "34 MemberExpression=$$=False=$$=False\n",
      "35 FunctionDeclaration=$$=True=$$=False\n",
      "36 ObjectExpression=$$=False=$$=True\n",
      "37 ExpressionStatement=$$=False=$$=False\n",
      "38 UnaryExpression=$$=False=$$=False\n",
      "39 DoWhileStatement=$$=True=$$=True\n",
      "40 SwitchCase=$$=False=$$=False\n",
      "41 BinaryExpression=$$=False=$$=False\n",
      "42 ArrayAccess=$$=True=$$=True\n",
      "43 ThrowStatement=$$=True=$$=True\n",
      "44 NewExpression=$$=True=$$=False\n",
      "45 SwitchCase=$$=True=$$=False\n",
      "46 BinaryExpression=$$=True=$$=False\n",
      "47 ThrowStatement=$$=False=$$=False\n",
      "48 AssignmentPattern=$$=True=$$=False\n",
      "49 BinaryExpression=$$=True=$$=True\n",
      "50 CatchClause=$$=True=$$=False\n",
      "51 ArrayExpression=$$=True=$$=False\n",
      "52 FunctionExpression=$$=False=$$=True\n",
      "53 WhileStatement=$$=False=$$=False\n",
      "54 SwitchCase=$$=True=$$=True\n",
      "55 ReturnStatement=$$=True=$$=False\n",
      "56 Property=$$=False=$$=False\n",
      "57 NewExpression=$$=False=$$=False\n",
      "58 ReturnStatement=$$=False=$$=True\n",
      "59 ReturnStatement=$$=True=$$=True\n",
      "60 LogicalExpression=$$=False=$$=True\n",
      "61 MemberExpression=$$=True=$$=False\n",
      "62 CatchClause=$$=True=$$=True\n",
      "63 ConditionalExpression=$$=True=$$=False\n",
      "64 SwitchCase=$$=False=$$=True\n",
      "65 VariableDeclaration=$$=True=$$=True\n",
      "66 LogicalExpression=$$=True=$$=False\n",
      "67 ThrowStatement=$$=True=$$=False\n",
      "68 LabeledStatement=$$=False=$$=True\n",
      "69 SwitchStatement=$$=True=$$=True\n",
      "70 MemberExpression=$$=True=$$=True\n",
      "71 Program=$$=False=$$=True\n",
      "72 ForStatement=$$=True=$$=False\n",
      "73 SequenceExpression=$$=False=$$=True\n",
      "74 ForStatement=$$=True=$$=True\n",
      "75 VariableDeclaration=$$=False=$$=False\n",
      "76 ArrayAccess=$$=True=$$=False\n",
      "77 IfStatement=$$=False=$$=True\n",
      "78 MemberExpression=$$=False=$$=True\n",
      "79 CallExpression=$$=False=$$=True\n",
      "80 ThrowStatement=$$=False=$$=True\n",
      "81 FunctionExpression=$$=False=$$=False\n",
      "82 ExpressionStatement=$$=True=$$=True\n",
      "83 WhileStatement=$$=False=$$=True\n",
      "84 UnaryExpression=$$=True=$$=False\n",
      "85 ObjectExpression=$$=True=$$=True\n",
      "86 WhileStatement=$$=True=$$=True\n",
      "87 VariableDeclaration=$$=True=$$=False\n",
      "88 VariableDeclaration=$$=False=$$=True\n",
      "89 ArrayExpression=$$=False=$$=True\n",
      "90 LabeledStatement=$$=False=$$=False\n",
      "91 BinaryExpression=$$=False=$$=True\n",
      "92 DoWhileStatement=$$=False=$$=True\n",
      "93 IfStatement=$$=False=$$=False\n",
      "94 VariableDeclarator=$$=True=$$=False\n",
      "95 CallExpression=$$=False=$$=False\n",
      "96 FunctionExpression=$$=True=$$=False\n",
      "97 Property=$$=True=$$=True\n",
      "98 SequenceExpression=$$=False=$$=False\n",
      "99 ForStatement=$$=False=$$=False\n",
      "100 ForStatement=$$=False=$$=True\n",
      "101 VariableDeclarator=$$=False=$$=False\n",
      "102 ForInStatement=$$=True=$$=False\n",
      "103 BlockStatement=$$=True=$$=True\n",
      "104 TryStatement=$$=True=$$=True\n",
      "105 LabeledStatement=$$=True=$$=False\n",
      "106 SwitchStatement=$$=True=$$=False\n",
      "107 DoWhileStatement=$$=False=$$=False\n",
      "108 ArrayExpression=$$=False=$$=False\n",
      "109 FunctionDeclaration=$$=False=$$=True\n",
      "110 VariableDeclarator=$$=False=$$=True\n",
      "111 Property=$$=True=$$=False\n",
      "112 IfStatement=$$=True=$$=True\n",
      "113 ForInStatement=$$=False=$$=False\n",
      "114 LogicalExpression=$$=False=$$=False\n",
      "115 BlockStatement=$$=False=$$=True\n",
      "116 SwitchStatement=$$=False=$$=True\n",
      "117 FunctionDeclaration=$$=True=$$=True\n",
      "118 NewExpression=$$=True=$$=True\n",
      "119 LabeledStatement=$$=True=$$=True\n",
      "120 BlockStatement=$$=True=$$=False\n",
      "121 SwitchStatement=$$=False=$$=False\n",
      "122 CallExpression=$$=True=$$=False\n"
     ]
    }
   ],
   "source": [
    "for i, j in nt_int_to_token.items():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict():\n",
    "    nn_kinds = {}\n",
    "    for i, j in tt_int_to_token.items():\n",
    "        type_info = j.split('=$$=')[0]\n",
    "        nn_kinds[type_info] = nn_kinds.get(type_info, 0) + 1\n",
    "    return nn_kinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa():\n",
    "    kinds = []\n",
    "    for i, j in tt_int_to_token.items():\n",
    "        kinds.append(j)\n",
    "        if i%100 == 0:\n",
    "            yield kinds\n",
    "            kinds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aaa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "nt_count, tt_count = pickle.load(open('count_statistic.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'MemberExpression': 20134801, 'CallExpression': 10258247, 'ExpressionStatement': 9450529, 'BlockStatement': 6821809, 'Property': 5906407, 'BinaryExpression': 5628505, 'AssignmentExpression': 5576605, 'VariableDeclarator': 3476297, 'IfStatement': 2936278, 'VariableDeclaration': 2814260, 'FunctionExpression': 2670629, 'ArrayAccess': 2543137, 'ReturnStatement': 2029991, 'LogicalExpression': 1889386, 'UnaryExpression': 1553437, 'ObjectExpression': 1515810, 'ArrayExpression': 1120577, 'ConditionalExpression': 598759, 'NewExpression': 473855, 'UpdateExpression': 448388, 'FunctionDeclaration': 423768, 'SwitchCase': 294829, 'ForStatement': 282726, 'WhileStatement': 120169, 'Program': 99921, 'ThrowStatement': 95579, 'ForInStatement': 89481, 'SequenceExpression': 83993, 'TryStatement': 63064, 'CatchClause': 60745, 'SwitchStatement': 37515, 'DoWhileStatement': 9822, 'LabeledStatement': 3557, 'AssignmentPattern': 4})\n"
     ]
    }
   ],
   "source": [
    "print(nt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Identifier': 35936943, 'Property': 21313066, 'LiteralString': 9118212, 'LiteralNumber': 7958932, 'ThisExpression': 4083740, 'LiteralBoolean': 1186922, 'VariableDeclarator': 1011573, 'LiteralNull': 628911, 'ArrayExpression': 317362, 'ObjectExpression': 272414, 'LiteralRegExp': 236001, 'BreakStatement': 213773, 'EmptyStatement': 205002, 'BlockStatement': 169926, 'ReturnStatement': 155185, 'ContinueStatement': 31704})\n"
     ]
    }
   ],
   "source": [
    "print(tt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MemberExpression', 20134801),\n",
       " ('CallExpression', 10258247),\n",
       " ('ExpressionStatement', 9450529),\n",
       " ('BlockStatement', 6821809),\n",
       " ('Property', 5906407),\n",
       " ('BinaryExpression', 5628505),\n",
       " ('AssignmentExpression', 5576605),\n",
       " ('VariableDeclarator', 3476297),\n",
       " ('IfStatement', 2936278),\n",
       " ('VariableDeclaration', 2814260),\n",
       " ('FunctionExpression', 2670629),\n",
       " ('ArrayAccess', 2543137),\n",
       " ('ReturnStatement', 2029991),\n",
       " ('LogicalExpression', 1889386),\n",
       " ('UnaryExpression', 1553437),\n",
       " ('ObjectExpression', 1515810),\n",
       " ('ArrayExpression', 1120577),\n",
       " ('ConditionalExpression', 598759),\n",
       " ('NewExpression', 473855),\n",
       " ('UpdateExpression', 448388),\n",
       " ('FunctionDeclaration', 423768),\n",
       " ('SwitchCase', 294829),\n",
       " ('ForStatement', 282726),\n",
       " ('WhileStatement', 120169),\n",
       " ('Program', 99921),\n",
       " ('ThrowStatement', 95579),\n",
       " ('ForInStatement', 89481),\n",
       " ('SequenceExpression', 83993),\n",
       " ('TryStatement', 63064),\n",
       " ('CatchClause', 60745),\n",
       " ('SwitchStatement', 37515),\n",
       " ('DoWhileStatement', 9822),\n",
       " ('LabeledStatement', 3557),\n",
       " ('AssignmentPattern', 4)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_x = [a for a, b in nt_count.most_common()]\n",
    "nt_y = [b for a, b in nt_count.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'number of each token')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(nt_x, nt_y)\n",
    "plt.xlabel('non-terminal token')\n",
    "plt.ylabel('number of each token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "tt_x = [k for k, v in tt_count.most_common()]\n",
    "tt_y = [v for k, v in tt_count.most_common()]\n",
    "tt_xx = tt_x[:6]\n",
    "tt_yy = tt_y[:6]\n",
    "other_count = 0\n",
    "for i in range(6, len(tt_y)):\n",
    "    other_count += tt_y[i]\n",
    "tt_xx.append('otherTokens')\n",
    "tt_yy.append(other_count)\n",
    "plt.bar(tt_xx, tt_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'ThisExpression'),\n",
       " (2, 'LiteralNumber=$$=0'),\n",
       " (3, 'LiteralNumber=$$=1'),\n",
       " (4, 'Identifier=$$=i'),\n",
       " (5, 'Property=$$=length'),\n",
       " (6, 'LiteralBoolean=$$=true'),\n",
       " (7, 'LiteralNull=$$=null'),\n",
       " (8, 'Identifier=$$=elem'),\n",
       " (9, 'LiteralBoolean=$$=false'),\n",
       " (10, 'Identifier=$$=jQuery'),\n",
       " (11, 'Identifier=$$=value'),\n",
       " (12, 'LiteralNumber=$$=2'),\n",
       " (13, 'Identifier=$$=$'),\n",
       " (14, 'Property=$$=i'),\n",
       " (15, 'Property=$$=prototype'),\n",
       " (16, 'LiteralString=$$='),\n",
       " (17, 'Identifier=$$=e'),\n",
       " (18, 'Identifier=$$=options'),\n",
       " (19, 'Identifier=$$=name'),\n",
       " (20, 'Identifier=$$=data'),\n",
       " (21, 'ArrayExpression'),\n",
       " (22, 'ObjectExpression'),\n",
       " (23, 'Property=$$=push'),\n",
       " (24, 'Identifier=$$=self'),\n",
       " (25, 'Identifier=$$=node'),\n",
       " (26, 'Identifier=$$=event'),\n",
       " (27, 'Identifier=$$=a'),\n",
       " (28, 'Property=$$=call'),\n",
       " (29, 'Identifier=$$=obj'),\n",
       " (30, 'Identifier=$$=type'),\n",
       " (31, 'Identifier=$$=require'),\n",
       " (32, 'Identifier=$$=s'),\n",
       " (33, 'Identifier=$$=context'),\n",
       " (34, 'EmptyStatement'),\n",
       " (35, 'Identifier=$$=undefined'),\n",
       " (36, 'Property=$$=name'),\n",
       " (37, 'Identifier=$$=arguments'),\n",
       " (38, 'Property=$$=type'),\n",
       " (39, 'Identifier=$$=callback'),\n",
       " (40, 'Identifier=$$=key'),\n",
       " (41, 'BreakStatement'),\n",
       " (42, 'Identifier=$$=x'),\n",
       " (43, 'Identifier=$$=b'),\n",
       " (44, 'LiteralNumber=$$=3'),\n",
       " (45, 'Identifier=$$=o'),\n",
       " (46, 'Identifier=$$=element'),\n",
       " (47, 'Identifier=$$=document'),\n",
       " (48, 'Identifier=$$=Math'),\n",
       " (49, 'Identifier=$$=selector'),\n",
       " (50, 'ReturnStatement'),\n",
       " (51, 'Identifier=$$=t'),\n",
       " (52, 'Identifier=$$=result'),\n",
       " (53, 'Identifier=$$=fn'),\n",
       " (54, 'Identifier=$$=c'),\n",
       " (55, 'Identifier=$$=val'),\n",
       " (56, 'Identifier=$$=index'),\n",
       " (57, 'Identifier=$$=args'),\n",
       " (58, 'Identifier=$$=window'),\n",
       " (59, 'Property=$$=value'),\n",
       " (60, 'Identifier=$$=d'),\n",
       " (61, 'BlockStatement'),\n",
       " (62, 'Property=$$=get'),\n",
       " (63, 'Identifier=$$=n'),\n",
       " (64, 'Identifier=$$=module'),\n",
       " (65, 'Property=$$=replace'),\n",
       " (66, 'Property=$$=options'),\n",
       " (67, 'Property=$$=data'),\n",
       " (68, 'Identifier=$$=match'),\n",
       " (69, 'Identifier=$$=ret'),\n",
       " (70, 'Property=$$=id'),\n",
       " (71, 'Property=$$=style'),\n",
       " (72, 'Property=$$=x'),\n",
       " (73, 'LiteralNumber=$$=4'),\n",
       " (74, 'Identifier=$$=j'),\n",
       " (75, 'Property=$$=test'),\n",
       " (76, 'Identifier=$$=exports'),\n",
       " (77, 'Identifier=$$=goog'),\n",
       " (78, 'Property=$$=apply'),\n",
       " (79, 'Property=$$=y'),\n",
       " (80, 'Identifier=$$=err'),\n",
       " (81, 'Identifier=$$=p'),\n",
       " (82, 'Identifier=$$=_'),\n",
       " (83, 'Identifier=$$=state'),\n",
       " (84, 'LiteralString=$$=string'),\n",
       " (85, 'Identifier=$$=el'),\n",
       " (86, 'Property=$$=each'),\n",
       " (87, 'Identifier=$$=assert'),\n",
       " (88, 'Identifier=$$=test'),\n",
       " (89, 'Property=$$=key'),\n",
       " (90, 'Identifier=$$=that'),\n",
       " (91, 'Identifier=$$=v'),\n",
       " (92, 'Identifier=$$=target'),\n",
       " (93, 'Identifier=$$=item'),\n",
       " (94, 'Property=$$=extend'),\n",
       " (95, 'LiteralString=$$= '),\n",
       " (96, 'LiteralNumber=$$=10'),\n",
       " (97, 'Property=$$=attr'),\n",
       " (98, 'Identifier=$$=y'),\n",
       " (99, 'Property=$$=nodeType'),\n",
       " (100, 'Identifier=$$=id')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_train_pair_dir = 'js_dataset/train_pair_data/nt_train_pair/part1.json'\n",
    "import pickle\n",
    "file = open(nt_train_pair_dir,'rb')\n",
    "data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(71, [65, 65, 65, 65, 65, 82, 109], [0]), (65, [71, 101], [0]), (101, [71, 65], [30000]), (65, [71, 101], [0]), (101, [71, 65], [30000]), (65, [71, 101], [0]), (101, [71, 65], [30000]), (65, [71, 101], [0]), (101, [71, 65], [16]), (65, [71, 101], [0]), (101, [71, 65], [16]), (82, [71, 95], [0]), (95, [71, 82], [88]), (109, [71, 115], [88]), (115, [71, 109, 82, 82, 82, 82, 82, 117, 82, 82, 82, 25], [0]), (82, [109, 115, 95], [0]), (95, [115, 82], [11117, 1030]), (82, [109, 115, 95], [0]), (95, [115, 82], [8482, 8044]), (82, [109, 115, 95], [0]), (95, [115, 82], [7727, 2886]), (82, [109, 115, 95], [0]), (95, [115, 82], [21026, 6]), (82, [109, 115, 36], [0]), (36, [115, 82, 11], [0]), (11, [82, 36, 8], [0]), (8, [36, 11, 108], [303]), (108, [11, 8], [3]), (117, [109, 115, 115], [134]), (115, [115, 117, 25], [0]), (25, [117, 115, 95], [0]), (95, [115, 25], [1381, 30000]), (82, [109, 115, 95], [0]), (95, [115, 82], [134]), (82, [109, 115, 95], [0]), (95, [115, 82], [21026, 9]), (82, [109, 115, 95], [0]), (95, [115, 82], [5815, 107, 557, 2886]), (25, [109, 115, 95], [0]), (95, [115, 25], [11220, 1030]), (71, [9, 65, 117, 82, 82, 82, 25], [0]), (9, [71], [248]), (65, [71, 110], [0]), (110, [71, 65, 95], [0]), (95, [65, 110], [31, 24074]), (117, [71, 115], [30000]), (115, [71, 117, 25], [0]), (25, [117, 115, 8], [0]), (8, [115, 25, 61], [22]), (61, [25, 8], [1, 1172])]\n",
      "(71, [65, 65, 65, 65, 65, 82, 109], [0])\n",
      "(65, [71, 101], [0])\n",
      "(101, [71, 65], [30000])\n",
      "(65, [71, 101], [0])\n",
      "(101, [71, 65], [30000])\n",
      "(65, [71, 101], [0])\n",
      "(101, [71, 65], [30000])\n",
      "(65, [71, 101], [0])\n",
      "(101, [71, 65], [16])\n",
      "(65, [71, 101], [0])\n",
      "(101, [71, 65], [16])\n",
      "(82, [71, 95], [0])\n",
      "(95, [71, 82], [88])\n",
      "(109, [71, 115], [88])\n",
      "(115, [71, 109, 82, 82, 82, 82, 82, 117, 82, 82, 82, 25], [0])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [11117, 1030])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [8482, 8044])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [7727, 2886])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [21026, 6])\n",
      "(82, [109, 115, 36], [0])\n",
      "(36, [115, 82, 11], [0])\n",
      "(11, [82, 36, 8], [0])\n",
      "(8, [36, 11, 108], [303])\n",
      "(108, [11, 8], [3])\n",
      "(117, [109, 115, 115], [134])\n",
      "(115, [115, 117, 25], [0])\n",
      "(25, [117, 115, 95], [0])\n",
      "(95, [115, 25], [1381, 30000])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [134])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [21026, 9])\n",
      "(82, [109, 115, 95], [0])\n",
      "(95, [115, 82], [5815, 107, 557, 2886])\n",
      "(25, [109, 115, 95], [0])\n",
      "(95, [115, 25], [11220, 1030])\n",
      "(71, [9, 65, 117, 82, 82, 82, 25], [0])\n",
      "(9, [71], [248])\n",
      "(65, [71, 110], [0])\n",
      "(110, [71, 65, 95], [0])\n",
      "(95, [65, 110], [31, 24074])\n",
      "(117, [71, 115], [30000])\n",
      "(115, [71, 117, 25], [0])\n",
      "(25, [117, 115, 8], [0])\n",
      "(8, [115, 25, 61], [22])\n",
      "(61, [25, 8], [1, 1172])\n"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(data), 50):\n",
    "    batch = data[index: index+50]\n",
    "    batch_x = []\n",
    "    batch_ny = []\n",
    "    batch_ty = []\n",
    "    for one_pair in batch:\n",
    "        print(one_pair)\n",
    "        batch_x.append(one_pair[0])\n",
    "        batch_ny.append(one_pair[1])\n",
    "        batch_ty.append(one_pair[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "from setting import Setting\n",
    "from utils import pickle_save\n",
    "\n",
    "base_setting = Setting()\n",
    "\n",
    "\n",
    "js_train_data_dir = base_setting.origin_train_data_dir\n",
    "\n",
    "data_parameter_dir = base_setting.data_parameter_dir\n",
    "\n",
    "train_pair_dir = 'js_dataset/train_pair_data/'\n",
    "\n",
    "num_sub_valid_data = base_setting.num_sub_valid_data\n",
    "num_sub_train_data = base_setting.num_sub_train_data\n",
    "num_sub_test_data = base_setting.num_sub_test_data\n",
    "\n",
    "most_common_termial_num = 30000\n",
    "unknown_token = base_setting.unknown_token\n",
    "time_steps = base_setting.time_steps\n",
    "\n",
    "\n",
    "\n",
    "def dataset_split(subset_size=5000):\n",
    "    \"\"\"è¯»å–åŽŸå§‹ASTæ•°æ®é›†ï¼Œå¹¶å°†å…¶åˆ†å‰²æˆå¤šä¸ªsubset data\n",
    "    å¯¹æ¯ä¸ªASTï¼Œç”Ÿæˆå¤šä¸ªtraining pair\"\"\"\n",
    "\n",
    "    data_path = js_train_data_dir\n",
    "    total_size = 100000\n",
    "    saved_to_path = train_pair_dir\n",
    "\n",
    "    file = open(data_path, 'r')\n",
    "    train_pairs_list = []\n",
    "    for i in range(1, total_size + 1):\n",
    "        try:\n",
    "            line = file.readline()  # read a lind from file(one ast)\n",
    "            ast = json.loads(line)  # transform it to json format\n",
    "            one_ast_pairs = generate_train_pair(ast)\n",
    "        except UnicodeDecodeError as error:  # arise by readline\n",
    "            print(error)\n",
    "        except JSONDecodeError as error:  # arise by json_load\n",
    "            print(error)\n",
    "        except RecursionError as error:\n",
    "            print(error)\n",
    "        except BaseException:\n",
    "            print('other unknown error, plesae check the code')\n",
    "        else:\n",
    "            train_pairs_list.append(one_ast_pairs)\n",
    "\n",
    "        if i % subset_size == 0:  # å½“è¯»å…¥çš„astå·²ç»ç­‰äºŽç»™å®šçš„subsetçš„å¤§å°æ—¶\n",
    "            sub_path = saved_to_path + \\\n",
    "                'part{}'.format(i // subset_size) + '.json'\n",
    "            pickle_save(sub_path, train_pairs_list)  # å°†subset datasetä¿å­˜\n",
    "            train_pairs_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_parameter():\n",
    "    path = data_parameter_dir\n",
    "    file = open(path, 'rb')\n",
    "    tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token = pickle.load(file)\n",
    "    return tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_bits_info(ast, node, brother_map):\n",
    "    # å‘æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸¤bitçš„é¢å¤–ä¿¡æ¯ï¼šhasNonTerminalChildå’ŒhasSibling\n",
    "    node['hasNonTerminalChild'] = False\n",
    "    for child_index in node['children']:\n",
    "        if 'children' in ast[child_index]:\n",
    "            node['hasNonTerminalChild'] = True\n",
    "            break\n",
    "    if brother_map.get(node['id'], -1) == -1:\n",
    "        node['hasSibling'] = False\n",
    "    else:\n",
    "        node['hasSibling'] = True\n",
    "\n",
    "def add_info(ast):\n",
    "    \"\"\"ç»™æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸€ä¸ªfather list\"\"\"\n",
    "    brother_map = {0:-1}\n",
    "    ast[0]['father'] = []  # ç»™æ ¹èŠ‚ç‚¹æ·»åŠ ä¸€ä¸ªç©ºçš„father list\n",
    "    info_ast = []\n",
    "    for index, node in enumerate(ast):\n",
    "        \n",
    "        if not isinstance(node, dict) and node == 0:  # ASTä¸­æœ€åŽæ·»åŠ ä¸€ä¸ª'EOFâ€™æ ‡è¯†\n",
    "            ast[index] = 'EOF'\n",
    "            break\n",
    "        \n",
    "        if 'children' in node.keys():\n",
    "            for child_index in node['children']:\n",
    "                child = ast[child_index]\n",
    "                child['father'] = []\n",
    "                child['father'].extend(node['father'])\n",
    "                child['father'].append(node['id'])\n",
    "        \n",
    "        if 'children' in node.keys():\n",
    "            node['isTerminal'] = False\n",
    "            add_two_bits_info(ast, node, brother_map)  # å‘èŠ‚ç‚¹æ·»åŠ é¢å¤–ä¸¤bitä¿¡æ¯\n",
    "            child_list = node['children']\n",
    "            for i, bro in enumerate(child_list):\n",
    "                if i == len(child_list) - 1:\n",
    "                    break\n",
    "                brother_map[bro] = child_list[i + 1]\n",
    "        else:\n",
    "            node['isTerminal'] = True\n",
    "    return ast\n",
    "\n",
    "def token_to_int(ast):\n",
    "    return int_ast\n",
    "\n",
    "def generate_train_pair(ast, nt_v_dim=2, tt_v_dim=2, tt_h_dim=2):\n",
    "    info_ast = add_info(ast)\n",
    "    int_ast = token_to_int(ast)\n",
    "    \n",
    "#     nt_train_pairs = []\n",
    "#     tt_train_pairs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import examples\n",
    "ast = ast_example = [{'id': 0, 'type': 'Program', 'children': [1]},\n",
    "                   {'id': 1, 'type': 'ExpressionStatement', 'children': [2]},\n",
    "                   {'id': 2, 'type': 'CallExpression', 'children': [3, 8, 9, 10]},\n",
    "                   {'id': 3, 'type': 'MemberExpression', 'children': [4, 7]},\n",
    "                   {'id': 4, 'type': 'MemberExpression', 'children': [5, 6]},\n",
    "                   {'id': 5, 'type': 'Identifier', 'value': 'CKEDITOR'},\n",
    "                   {'id': 6, 'type': 'Property', 'value': 'plugins'},\n",
    "                   {'id': 7, 'type': 'Property', 'value': 'setLang'},\n",
    "                   {'id': 8, 'type': 'LiteralString', 'value': 'iframe'},\n",
    "                   {'id': 9, 'type': 'LiteralString', 'value': 'ka'},\n",
    "                   {'id': 10, 'type': 'ObjectExpression', 'children': [11, 13, 15, 17, 19]},\n",
    "                   {'id': 11, 'type': 'Property', 'value': 'border', 'children': [12]},\n",
    "                   {'id': 12, 'type': 'LiteralString', 'value': 'áƒ©áƒáƒ áƒ©áƒáƒ¡ áƒ’áƒáƒ›áƒáƒ©áƒ”áƒœáƒ'},\n",
    "                   {'id': 13, 'type': 'Property', 'value': 'noUrl', 'children': [14]},\n",
    "                   {'id': 14, 'type': 'LiteralString', 'value': 'áƒáƒ™áƒ áƒ˜áƒ¤áƒ”áƒ— iframe-áƒ˜áƒ¡ URL'},\n",
    "                   {'id': 15, 'type': 'Property', 'value': 'scrolling', 'children': [16]},\n",
    "                   {'id': 16, 'type': 'LiteralString', 'value': 'áƒ’áƒáƒ“áƒáƒ®áƒ•áƒ”áƒ•áƒ˜áƒ¡ áƒ–áƒáƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ¨áƒ•áƒ”áƒ‘áƒ'},\n",
    "                   {'id': 17, 'type': 'Property', 'value': 'title', 'children': [18]},\n",
    "                   {'id': 18, 'type': 'LiteralString', 'value': 'IFrame-áƒ˜áƒ¡ áƒžáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜'},\n",
    "                   {'id': 19, 'type': 'Property', 'value': 'toolbar', 'children': [20]},\n",
    "                   {'id': 20, 'type': 'LiteralString', 'value': 'IFrame'}, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_ast = add_info(ast)\n",
    "print(info_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in info_ast:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "test_path = 'js_dataset/split_js_data/eval_data/int_format/int_part1.json'\n",
    "valid_path = 'js_dataset/split_js_data/valid_data/int_format/int_part1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pickle.load(open(test_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = pickle.load(open(valid_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(len(test_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(a)\n",
    "b = np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(repre_matrix_dir, 'wb')\n",
    "pickle.dump([a ,b], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(len(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "terminal_count = Counter()  # ç»Ÿè®¡æ¯ä¸ªterminal tokençš„å‡ºçŽ°æ¬¡æ•°\n",
    "non_terminal_set = set()  # ç»Ÿè®¡non_termial token ç§ç±»\n",
    "\n",
    "\n",
    "def ast_to_seq(binary_tree, run_or_process='process'):\n",
    "    # å°†ä¸€ä¸ªasté¦–å…ˆè½¬æ¢æˆäºŒå‰æ ‘ï¼Œç„¶åŽå¯¹è¯¥äºŒå‰æ ‘è¿›è¡Œä¸­åºéåŽ†ï¼Œå¾—åˆ°nt_sequence\n",
    "    temp_terminal_count = Counter()\n",
    "    temp_non_terminal_set = set()\n",
    "    def node_to_string(node):\n",
    "        # å°†ä¸€ä¸ªnodeè½¬æ¢ä¸ºstring\n",
    "        if node == 'EMPTY':\n",
    "            string_node = 'EMPTY'\n",
    "            temp_terminal_count[string_node] += 1\n",
    "        elif node['isTerminal']:  # å¦‚æžœnodeä¸ºterminal\n",
    "            string_node = str(node['type'])\n",
    "            if 'value' in node.keys():\n",
    "                # Note:There are some tokens(like:break .etcï¼‰do not contains 'value'\n",
    "                string_node += '=$$=' + str(node['value'])\n",
    "            temp_terminal_count[string_node] += 1\n",
    "\n",
    "        else:  # å¦‚æžœæ˜¯non-terminal\n",
    "\n",
    "            string_node = str(node['type']) + '=$$=' + \\\n",
    "                str(node['hasSibling']) + '=$$=' + \\\n",
    "                str(node['hasNonTerminalChild'])  # æœ‰äº›non-terminalåŒ…å«valueï¼ŒæŽ¢ç´¢è¯¥valueçš„æ„ä¹‰ï¼Ÿï¼ˆvalueç§ç±»éžå¸¸å¤šï¼‰\n",
    "            temp_non_terminal_set.add(string_node)\n",
    "\n",
    "        return string_node\n",
    "\n",
    "    def in_order_traversal(bin_tree, index):\n",
    "        # å¯¹ç»™å®šçš„äºŒå‰æ ‘è¿›è¡Œä¸­åºéåŽ†ï¼Œå¹¶åœ¨ä¸­åºéåŽ†çš„æ—¶å€™ï¼Œç”Ÿæˆnt_pair\n",
    "        node = bin_tree[index]\n",
    "        if 'left' in node.keys():\n",
    "            in_order_traversal(bin_tree, node['left'])\n",
    "\n",
    "        if node == 'EMPTY' or node['isTerminal'] is True:  # è¯¥tokenæ˜¯terminalï¼Œåªå°†å…¶è®°å½•åˆ°counterä¸­\n",
    "            node_to_string(node)\n",
    "        else:\n",
    "            assert 'isTerminal' in node.keys() and node['isTerminal'] is False\n",
    "            # å¦‚æžœè¯¥nodeæ˜¯non-terminalï¼Œå¹¶ä¸”åŒ…å«ä¸€ä¸ªterminal å­èŠ‚ç‚¹ï¼Œåˆ™å’Œè¯¥å­èŠ‚ç‚¹ç»„æˆnt_pairä¿å­˜åœ¨outputä¸­\n",
    "            # å¦åˆ™å°†nt_pairçš„Tè®¾ä¸ºå­—ç¬¦ä¸²EMPTY\n",
    "            n_pair = node_to_string(node)\n",
    "            for child_index in node['children']:  # éåŽ†è¯¥non-terminalçš„æ‰€æœ‰childï¼Œåˆ†åˆ«ç”¨æ‰€æœ‰childæž„å»ºNT-pair\n",
    "                if bin_tree[child_index]['isTerminal']:\n",
    "                    t_pair = node_to_string(bin_tree[child_index])\n",
    "                else:\n",
    "                    t_pair = node_to_string('EMPTY')\n",
    "                nt_pair = (n_pair, t_pair)\n",
    "                output.append(nt_pair)\n",
    "\n",
    "\n",
    "        if node['right'] != -1:  # éåŽ†right side\n",
    "            in_order_traversal(bin_tree, node['right'])\n",
    "\n",
    "    output = []\n",
    "    in_order_traversal(binary_tree, 0)\n",
    "\n",
    "    if run_or_process == 'run':\n",
    "        return output\n",
    "\n",
    "    if len(output) >= time_steps:  # note: ä»…å°†é•¿åº¦å¤§äºŽé˜ˆå€¼çš„astäº§ç”Ÿçš„nodeç»Ÿè®¡åˆ°counterä¸­\n",
    "        terminal_count.update(temp_terminal_count)\n",
    "        non_terminal_set.update(temp_non_terminal_set)\n",
    "    else:\n",
    "        output = []\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import utils\n",
    "\n",
    "def code_to_ast(code_path='js_parser/js_helloworld.js'):\n",
    "    out_bytes = subprocess.check_output('node js_parser/js_parser.js ' + code_path, shell=True)\n",
    "    out_text = out_bytes.decode('utf-8')\n",
    "    ast = json.loads(out_text)\n",
    "    binary_tree = utils.bulid_binary_tree(ast)\n",
    "    nt_seq = utils.ast_to_seq(binary_tree, run_or_process='run')\n",
    "    print(nt_seq)\n",
    "    \n",
    "    \n",
    "code_to_ast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import utils\n",
    "from basic_lstm import RnnModel\n",
    "from setting import Setting\n",
    "\n",
    "\n",
    "test_setting = Setting()\n",
    "test_subset_data_dir = test_setting.sub_int_test_dir\n",
    "model_save_dir = test_setting.lstm_model_save_dir\n",
    "test_log_dir = test_setting.lstm_test_log_dir\n",
    "\n",
    "\n",
    "num_subset_test_data = test_setting.num_sub_test_data\n",
    "seq_per_subset = 5000\n",
    "show_every_n = test_setting.test_show\n",
    "num_terminal = test_setting.num_terminal\n",
    "test_time_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortLongTest(object):\n",
    "    \"\"\"Record the performance with different length\"\"\"\n",
    "    def __init__(self,\n",
    "                 num_ntoken,\n",
    "                 num_ttoken,):\n",
    "        self.model = RnnModel(num_ntoken, num_ttoken, is_training=False)\n",
    "        self.sess = tf.Session()\n",
    "        self.last_chackpoints = tf.train.latest_checkpoint(\n",
    "            checkpoint_dir=model_save_dir)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, self.last_chackpoints)\n",
    "\n",
    "    def subset_generator(self):\n",
    "        for index in range(1, num_subset_test_data +1):\n",
    "            with open(test_subset_data_dir + 'int_part{}.json'.format(index), 'rb') as file:\n",
    "                subset_data = pickle.load(file)\n",
    "                yield index, subset_data\n",
    "\n",
    "    def find_long_seq(self, length_define=5000, saved_info=False):\n",
    "        \"\"\"pick up longer test cases in test dataset\"\"\"\n",
    "        long_case = []\n",
    "        subdata_generator = self.subset_generator()\n",
    "        length_counter = Counter()\n",
    "        for index, subset_test_data in subdata_generator:\n",
    "            for token_seq in subset_test_data:\n",
    "                length_counter[len(token_seq)] += 1\n",
    "                if len(token_seq) >= length_define:\n",
    "                    token_seq = token_seq[:length_define+1]\n",
    "                    long_case.append(token_seq)\n",
    "        sorted_counter = sorted(length_counter.items(), key=lambda x: x[0] ,reverse=True)\n",
    "        if saved_info:\n",
    "            pickle.dump(sorted_counter, open('longth_count_info.p', 'wb'))           \n",
    "        return long_case\n",
    "\n",
    "    def short_long_performance(self):\n",
    "        length_define = 5000\n",
    "        long_case = self.find_long_seq(length_define)\n",
    "        num_test_case = len(long_case)\n",
    "        long_case = np.array(long_case)  # long_case.shape = (258, 5001, 2)\n",
    "        print(long_case.shape)\n",
    "        test_epoch = 5\n",
    "        length_nt_correct = np.zeros(length_define, dtype=np.float32)\n",
    "        length_tt_correct = np.zeros(length_define, dtype=np.float32)\n",
    "\n",
    "        for i in range(test_epoch):\n",
    "            lstm_state = self.sess.run(self.model.init_state)\n",
    "            for test_case in long_case:\n",
    "                print(test_case.shape)\n",
    "                print(test_case[:length_define, 0].shape)\n",
    "                nt_token_input = test_case[:length_define, 0].reshape([1, length_define])\n",
    "                tt_token_input = test_case[:length_define, 1].reshape([1, length_define])\n",
    "                nt_token_target = test_case[1:length_define +1, 0]\n",
    "                tt_token_target = test_case[1:length_define +1, 1]\n",
    "                feed = {self.model.lstm_state: lstm_state,\n",
    "                        self.model.n_input :nt_token_input,\n",
    "                        self.model.t_input :tt_token_input,\n",
    "                        self.model.keep_prob :1.0}\n",
    "                lstm_state, n_prediction, t_prediction = self.sess.run(\n",
    "                    [self.model.final_state, self.model.n_output, self.model.t_output], feed)\n",
    "                n_prediction = np.argmax(n_prediction, axis=1)\n",
    "                t_prediction = np.argmax(t_prediction, axis=1)\n",
    "                nt_result = np.equal(n_prediction, nt_token_target).astype(np.float32)\n",
    "                tt_result = np.equal(t_prediction, tt_token_target).astype(np.float32)\n",
    "                length_nt_correct += nt_result\n",
    "                length_tt_correct += tt_result\n",
    "\n",
    "        nt_accuracy = length_nt_correct / (test_epoch * num_test_case)\n",
    "        tt_accuracy = length_tt_correct / (test_epoch * num_test_case)\n",
    "        file = open('short_long_performance.p', 'wb')\n",
    "        pickle.dump([nt_accuracy, tt_accuracy], file)\n",
    "\n",
    "        return nt_accuracy, tt_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token = utils.load_dict_parameter()\n",
    "num_ntoken = len(nt_token_to_int)\n",
    "num_ttoken = len(tt_token_to_int)\n",
    "model = ShortLongTest(num_ntoken, num_ttoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "nt_accuracy, tt_accuracy = pickle.load(open('new_short_long_performance.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 12))\n",
    "plt.plot(nt_accuracy, label='non-terminal')\n",
    "plt.plot(tt_accuracy, label='terminal')\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('performance with length')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(i, '  ', tt_accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(i , '  ' , nt_accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5000)\n",
    "xnew = np.linspace(x.min(), x.max(), 500)\n",
    "spl = make_interp_spline(x, nt_accuracy, k=3)\n",
    "smooth = spl(xnew)\n",
    "plt.plot(xnew, smooth)\n",
    "spl = make_interp_spline(x, tt_accuracy, k=3)\n",
    "smooth = spl(xnew)\n",
    "plt.plot(xnew, smooth)\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('performance with length')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nt_accuracy, label='non-terminal')\n",
    "plt.plot(tt_accuracy, label='terminal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "count = pickle.load(open('longth_count_info.p', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_count = sorted(count.items(), key=lambda x: x[0],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = 0\n",
    "for long, cou in sort_count:\n",
    "    if long >= 5000:\n",
    "        ccc += cou\n",
    "print(ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token = utils.load_dict_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nt_token_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt_token_to_int['WhileStatement=$$=False=$$=False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tt_int_to_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "path = 'js_dataset/js_programs_training.json'\n",
    "file = open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = file.readline()\n",
    "a = json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "count = Counter()\n",
    "path = 'split_js_data/train_data/int_format/'\n",
    "for i in range(1, 21):\n",
    "    a_path = path + 'int_part{}.json'.format(i)\n",
    "    data = pickle.load(open(a_path, 'rb'))\n",
    "    for n, t in data:\n",
    "        count[n] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(126):\n",
    "    if i not in count.keys():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt_int_to_token[49])\n",
    "print(nt_int_to_token[59])\n",
    "print(nt_int_to_token[123])\n",
    "# print(nt_int_to_token[99])\n",
    "'''\n",
    "BlockStatement=$$=True=$$=False\n",
    "LabeledStatement=$$=False=$$=False\n",
    "LabeledStatement=$$=True=$$=False\n",
    "IfStatement=$$=False=$$=False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt_token_to_int['LabeledStatement=$$=False=$$=False'])\n",
    "count[124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt_token_to_int['BlockStatement=$$=True=$$=False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt_int_to_token)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "\n",
    "sentences = word2vec.Text8Corpus('text8')\n",
    "model = word2vec.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_example = [{'id': 0, 'type': 'Program', 'children': [1]},\n",
    "                   {'id': 1, 'type': 'ExpressionStatement', 'children': [2]},\n",
    "                   {'id': 2, 'type': 'CallExpression', 'children': [3, 8, 9, 10]},\n",
    "                   {'id': 3, 'type': 'MemberExpression', 'children': [4, 7]},\n",
    "                   {'id': 4, 'type': 'MemberExpression', 'children': [5, 6]},\n",
    "                   {'id': 5, 'type': 'Identifier', 'value': 'CKEDITOR'},\n",
    "                   {'id': 6, 'type': 'Property', 'value': 'plugins'},\n",
    "                   {'id': 7, 'type': 'Property', 'value': 'setLang'},\n",
    "                   {'id': 8, 'type': 'LiteralString', 'value': 'iframe'},\n",
    "                   {'id': 9, 'type': 'LiteralString', 'value': 'ka'},\n",
    "                   {'id': 10, 'type': 'ObjectExpression', 'children': [11, 13, 15, 17, 19]},\n",
    "                   {'id': 11, 'type': 'Property', 'value': 'border', 'children': [12]},\n",
    "                   {'id': 12, 'type': 'LiteralString', 'value': 'áƒ©áƒáƒ áƒ©áƒáƒ¡ áƒ’áƒáƒ›áƒáƒ©áƒ”áƒœáƒ'},\n",
    "                   {'id': 13, 'type': 'Property', 'value': 'noUrl', 'children': [14]},\n",
    "                   {'id': 14, 'type': 'LiteralString', 'value': 'áƒáƒ™áƒ áƒ˜áƒ¤áƒ”áƒ— iframe-áƒ˜áƒ¡ URL'},\n",
    "                   {'id': 15, 'type': 'Property', 'value': 'scrolling', 'children': [16]},\n",
    "                   {'id': 16, 'type': 'LiteralString', 'value': 'áƒ’áƒáƒ“áƒáƒ®áƒ•áƒ”áƒ•áƒ˜áƒ¡ áƒ–áƒáƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ¨áƒ•áƒ”áƒ‘áƒ'},\n",
    "                   {'id': 17, 'type': 'Property', 'value': 'title', 'children': [18]},\n",
    "                   {'id': 18, 'type': 'LiteralString', 'value': 'IFrame-áƒ˜áƒ¡ áƒžáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜'},\n",
    "                   {'id': 19, 'type': 'Property', 'value': 'toolbar', 'children': [20]},\n",
    "                   {'id': 20, 'type': 'LiteralString', 'value': 'IFrame'}, 0]\n",
    "\n",
    "\n",
    "def bulid_binary_tree(ast):\n",
    "    \"\"\"transform the AST(one node may have several childNodes) to\n",
    "    Left-Child-Right-Sibling(LCRS) binary tree.\"\"\"\n",
    "    brother_map = {0: -1}\n",
    "    for index, node in enumerate(ast):  # é¡ºåºéåŽ†æ¯ä¸ªASTä¸­çš„node\n",
    "\n",
    "        if not isinstance(node, dict) and node == 0:  # ASTä¸­æœ€åŽæ·»åŠ ä¸€ä¸ª'EOFâ€™æ ‡è¯†\n",
    "            ast[index] = 'EOF'\n",
    "            break  # return data\n",
    "\n",
    "        node['right'] = brother_map.get(node['id'], -1)\n",
    "\n",
    "        if 'children' in node.keys():  # è¡¨ç¤ºè¯¥nodeä¸ºnon-terminal\n",
    "            node['isTerminal'] = False\n",
    "            add_two_bits_info(ast, node, brother_map)  # å‘æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸¤bitçš„é¢å¤–ä¿¡æ¯\n",
    "            child_list = node['children']\n",
    "            node['left'] = child_list[0]  # æž„å»ºè¯¥nodeçš„left node\n",
    "            for i, bro in enumerate(child_list):  # ä¸ºè¯¥nodeçš„æ‰€æœ‰childrenæž„å»ºright sibling\n",
    "                if i == len(child_list) - 1:\n",
    "                    break\n",
    "                brother_map[bro] = child_list[i + 1]\n",
    "        else:\n",
    "            node['isTerminal'] = True\n",
    "    return ast\n",
    "\n",
    "\n",
    "def add_two_bits_info(ast, node, brother_map):\n",
    "    # å‘æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸¤bitçš„é¢å¤–ä¿¡æ¯ï¼šhasNonTerminalChildå’ŒhasSibling\n",
    "    node['hasNonTerminalChild'] = False\n",
    "    for child_index in node['children']:\n",
    "        if 'children' in ast[child_index]:\n",
    "            node['hasNonTerminalChild'] = True\n",
    "            break\n",
    "    if brother_map.get(node['id'], -1) == -1:\n",
    "        node['hasSibling'] = False\n",
    "    else:\n",
    "        node['hasSibling'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "tt_token_to_int, tt_int_to_token, nt_token_to_int, nt_int_to_token = utils.load_dict_parameter()\n",
    "print(len(tt_token_to_int))\n",
    "print(len(nt_token_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_tree = bulid_binary_tree(ast_example)\n",
    "bin_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ast_to_seq(binary_tree):\n",
    "    # å°†ä¸€ä¸ªasté¦–å…ˆè½¬æ¢æˆäºŒå‰æ ‘ï¼Œç„¶åŽå¯¹è¯¥äºŒå‰æ ‘è¿›è¡Œä¸­åºéåŽ†ï¼Œå¾—åˆ°nt_sequence\n",
    "    def node_to_string(node):\n",
    "        # å°†ä¸€ä¸ªnodeè½¬æ¢ä¸ºstring\n",
    "        if node == 'EMPTY':\n",
    "            string_node = 'EMPTY'\n",
    "        elif node['isTerminal']:  # å¦‚æžœnodeä¸ºterminal\n",
    "            string_node = str(node['type']) + '=$$=' + \\\n",
    "                str(node['value'])   + '==' + str(node['id'])\n",
    "            terminal_count[string_node] += 1\n",
    "        else:  # å¦‚æžœæ˜¯non-terminal\n",
    "            string_node = str(node['type']) + '=$$=' + \\\n",
    "                str(node['hasSibling']) + '=$$=' + \\\n",
    "                str(node['hasNonTerminalChild'])  + str(node['id'])\n",
    "                # æœ‰äº›non-terminalåŒ…å«valueï¼ŒæŽ¢ç´¢è¯¥valueçš„æ„ä¹‰ï¼Ÿï¼ˆvalueç§ç±»éžå¸¸å¤šï¼‰\n",
    "            non_termial_set.add(string_node)\n",
    "        return string_node\n",
    "\n",
    "    def in_order_traversal(bin_tree, index):\n",
    "        # å¯¹ç»™å®šçš„äºŒå‰æ ‘è¿›è¡Œä¸­åºéåŽ†ï¼Œå¹¶åœ¨ä¸­åºéåŽ†çš„æ—¶å€™ï¼Œç”Ÿæˆnt_pair\n",
    "        node = bin_tree[index]\n",
    "        if 'left' in node.keys():\n",
    "            in_order_traversal(bin_tree, node['left'])\n",
    "\n",
    "        if 'isTerminal' in node.keys() and node['isTerminal'] is False:\n",
    "            # å¦‚æžœè¯¥nodeæ˜¯non-terminalï¼Œå¹¶ä¸”åŒ…å«ä¸€ä¸ªterminal å­èŠ‚ç‚¹ï¼Œåˆ™å’Œè¯¥å­èŠ‚ç‚¹ç»„æˆnt_pairä¿å­˜åœ¨outputä¸­\n",
    "            # å¦åˆ™å°†nt_pairçš„Tè®¾ä¸ºå­—ç¬¦ä¸²EMPTY\n",
    "            n_pair = node_to_string(node)\n",
    "            for child_index in node['children']:  # éåŽ†è¯¥Nterminalçš„æ‰€æœ‰childï¼Œåˆ†åˆ«ç”¨æ‰€æœ‰childæž„å»ºNT-pair\n",
    "                if bin_tree[child_index]['isTerminal']:\n",
    "                    t_pair = node_to_string(bin_tree[child_index])\n",
    "                else:\n",
    "                    t_pair = node_to_string('EMPTY')\n",
    "                nt_pair = (n_pair, t_pair)\n",
    "                output.append(nt_pair)\n",
    "\n",
    "            # if bin_tree[node['left']]['isTerminal']:\n",
    "            #     assert bin_tree[node['left']]['id'] == node['left']\n",
    "            #     t_pair = node_to_string(bin_tree[node['left']])\n",
    "            # else:\n",
    "            #     t_pair = node_to_string('EMPTY')\n",
    "            # nt_pair = (n_pair, t_pair)\n",
    "            # output.append(nt_pair)\n",
    "        else:  # è¯¥tokenæ˜¯terminalï¼Œåªå°†å…¶è®°å½•åˆ°counterä¸­\n",
    "            node_to_string(node)\n",
    "\n",
    "        if node['right'] != -1:  # éåŽ†right side\n",
    "            in_order_traversal(bin_tree, node['right'])\n",
    "\n",
    "    output = []\n",
    "    in_order_traversal(binary_tree, 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "terminal_count = Counter()  # ç»Ÿè®¡æ¯ä¸ªterminal tokençš„å‡ºçŽ°æ¬¡æ•°\n",
    "non_termial_set = set()  # ç»Ÿè®¡non_termial token ç§ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ast_to_seq(bin_tree)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "js_test_data_dir = 'js_dataset/js_programs_eval.json'\n",
    "js_train_data_dir = 'js_dataset/js_programs_training.json'\n",
    "\n",
    "def dataset_split(is_training=True, subset_size=5000):\n",
    "    if is_training:\n",
    "        data_path = js_train_data_dir\n",
    "        total_size = 100000\n",
    "        saved_to_path = 'split_js_data/train_data/'\n",
    "    else:\n",
    "        data_path = js_test_data_dir\n",
    "        total_size = 50000\n",
    "        saved_to_path = 'split_js_data/eval_data/'\n",
    "\n",
    "    file = open(data_path, 'r')\n",
    "    subset_list = []\n",
    "    error_count = 0\n",
    "    for i in range(1, total_size + 1):\n",
    "        try:\n",
    "            line = file.readline()\n",
    "            line = json.loads(line)\n",
    "            nt_seq = ast_to_seq(line)\n",
    "        except:\n",
    "            error_count += 1\n",
    "           # print('UTF-8 error: {}/{}'.format(error_count, i))\n",
    "        subset_list.append(nt_seq)\n",
    "        if i % subset_size == 0:\n",
    "#             sub_path = saved_to_path + 'part{}'.format(i // subset_size) + '.json'\n",
    "#             save_file = open(sub_path, 'wb')\n",
    "#             pickle.dump(subset_list, save_file)\n",
    "            subset_list = []\n",
    "    print('data seperating finished..., utf-8 error:{}'.format(error_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_bits_info(node, brother_map):\n",
    "    # å‘æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸¤bitçš„é¢å¤–ä¿¡æ¯ï¼šisTerminalå’ŒhasSibling\n",
    "    if 'children' in node.keys():\n",
    "        node['isTerminal'] = False\n",
    "    else:\n",
    "        node['isTerminal'] = True\n",
    "    if brother_map.get(node['id'], -1) == -1:\n",
    "        node['hasSibling'] = False\n",
    "    else:\n",
    "        node['hasSibling'] = True\n",
    "\n",
    "\n",
    "def bulid_binary_tree(data):\n",
    "    '''\n",
    "    transform the AST(one node may have several childNodes) to \n",
    "    Left-Child-Right-Sibling(LCRS) binary tree.\n",
    "    '''\n",
    "    brother_map = {0: -1}\n",
    "    for index, node in enumerate(data): # é¡ºåºéåŽ†æ¯ä¸ªASTä¸­çš„node\n",
    "        if type(node) != dict and node == 0: # ASTä¸­æœ€åŽæ·»åŠ ä¸€ä¸ª'EOFâ€™æ ‡è¯†\n",
    "            data[index] = 'EOF'\n",
    "            return data\n",
    "        # å‘æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸¤bitçš„é¢å¤–ä¿¡æ¯\n",
    "        add_two_bits_info(node, brother_map)\n",
    "        node['right'] = brother_map.get(node['id'], -1)\n",
    "        # è¡¨ç¤ºè¯¥nodeä¸ºnon-terminal\n",
    "        if 'children' in node.keys():\n",
    "            child_list = node['children']\n",
    "            node['left'] = child_list[0] # æž„å»ºè¯¥nodeçš„left node\n",
    "            for i, bro in enumerate(child_list): # ä¸ºè¯¥nodeçš„æ‰€æœ‰childrenæž„å»ºright sibling\n",
    "                if i == len(child_list)-1:\n",
    "                    break\n",
    "                brother_map[bro] = child_list[i+1]\n",
    "            node.pop('children')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token2int = {}\n",
    "int2token = {}\n",
    "terminalCountMap = Counter()\n",
    "nonTerminalSet =  set()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def ast_to_seq(data):\n",
    "    bi_tree = bulid_binary_tree(data)\n",
    " #   print(bi_tree)\n",
    "    \n",
    "    def node_to_string(node):\n",
    "        if node == 'EMPTY':\n",
    "            string_node = 'EMPTY'\n",
    "        elif node['isTerminal']:  # å¦‚æžœnodeä¸ºterminal\n",
    "            string_node = str(node['type'])+'=$$='+str(node['value']) ## + '==' + str(node['id'])\n",
    "            terminalCountMap[string_node] += 1\n",
    "        else:  # if it is a non-terminal\n",
    "            string_node = str(node['type']) + '=$$=' + \\\n",
    "                          str(node['hasSibling']) + '=$$=' + \\\n",
    "                          str(node['isTerminal']) # + '==' +str(node['id'])\n",
    "            if 'value' in node.keys(): # Note:There are some non-terminal contains 'value', use it?\n",
    "                string_node += '=$$=' + str(node['value'])\n",
    "            nonTerminalSet.add(string_node)\n",
    "            # todo: display the set of nonTerSet\n",
    "        return string_node\n",
    "\n",
    "    def in_order_traversal(data, index):\n",
    "        node = data[index]\n",
    "        if 'left' in node.keys():\n",
    "            in_order_traversal(data, node['left'])\n",
    "        # å¦‚æžœè¯¥èŠ‚ç‚¹ä¸ºnon-terminalï¼Œåˆ™æž„å»ºNT-pairå¹¶åŠ å…¥åˆ°sequenceä¸­ã€‚\n",
    "        if 'isTerminal' in node.keys() and node['isTerminal'] == False:\n",
    "            '''å¦‚æžœè¯¥nodeæ˜¯non-terminal\n",
    "            å¦‚æžœè¯¥non-terminalåŒ…å«ä¸€ä¸ªterminal å­èŠ‚ç‚¹ï¼Œåˆ™å’Œè¯¥å­èŠ‚ç‚¹ç»„æˆNT_pairä¿å­˜åœ¨outputä¸­\n",
    "            å¦åˆ™å°†NT_pairçš„Tè®¾ä¸ºå­—ç¬¦ä¸²EMPTY'''\n",
    "            N_pair = node_to_string(node)\n",
    "            T_pair = None\n",
    "            if data[node['left']]['isTerminal']==True:\n",
    "                assert data[node['left']]['id'] == node['left']\n",
    "                T_pair = node_to_string(data[node['left']])\n",
    "            else:\n",
    "                T_pair = node_to_string('EMPTY')\n",
    "            NT_pair = (N_pair, T_pair)\n",
    "            output.append(NT_pair)\n",
    "        else:\n",
    "            node_to_string(node)\n",
    "        # éåŽ†right side\n",
    "        if node['right'] != -1:\n",
    "            in_order_traversal(data, node['right'])\n",
    "    output = []\n",
    "    in_order_traversal(bi_tree, 0)\n",
    "    return output\n",
    "\n",
    "output = ast_to_seq(ast_example)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameter_dir = 'split_js_data/parameter.p'\n",
    "def load_dict_parameter():\n",
    "    file = open(data_parameter_dir, 'rb')\n",
    "    terminalToken2int, terminalInt2token, nonTerminalToken2int, nonTerminalInt2token = pickle.load(file)\n",
    "    return terminalToken2int, terminalInt2token, nonTerminalToken2int, nonTerminalInt2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminalToken2int, terminalInt2token, nonTerminalToken2int, nonTerminalInt2token = load_dict_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminalToken2int, terminalInt2token, nonTerminalToken2int, nonTerminalInt2token = load_dict_parameter()\n",
    "print(len(nonTerminalInt2token))\n",
    "print(len(terminalInt2token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nt_seq(time_steps=50):\n",
    "    '''\n",
    "    å¯¹å·²ç»å¤„ç†å¥½çš„NT seqè¿›è¡Œè¿›ä¸€æ­¥çš„å¤„ç†ï¼Œ\n",
    "    é¦–å…ˆå°†æ¯ä¸ªtokenè½¬æ¢ä¸ºnumberï¼Œç„¶åŽæˆªå–å„ä¸ªseqæˆ50çš„å€æ•°ï¼Œï¼ˆ50ä¸ºtime-stepså¤§å°ï¼‰\n",
    "    ç„¶åŽå°†æ¯ä¸ªASTéƒ½æ‹¼æŽ¥åˆ°ä¸€èµ·ï¼Œ\n",
    "    '''\n",
    "    terminalToken2int, terminalInt2token, nonTerminalToken2int, nonTerminalInt2token = load_dict_parameter()\n",
    "    num_subset_train_data = 20\n",
    "    subset_data_dir = 'split_js_data/train_data/'\n",
    "    total_num_nt_pair = 0\n",
    "    \n",
    "    def get_subset_data(): #å¯¹æ¯ä¸ªpartçš„nt_sequenceè¯»å–å¹¶è¿”å›žï¼Œç­‰å¾…è¿›è¡Œå¤„ç†\n",
    "        for i in range(1, num_subset_train_data + 1):\n",
    "            data_path = subset_data_dir + f'part{i}.json'\n",
    "            file = open(data_path, 'rb')\n",
    "            data = pickle.load(file)\n",
    "            yield (i, data)\n",
    "\n",
    "    subset_generator = get_subset_data()\n",
    "    for index, data in subset_generator:\n",
    "#        data = pickle.load(open(subset_data_dir+'part1.json', 'rb'))\n",
    "        data_seq = []\n",
    "        for one_ast in data: # å°†æ¯ä¸ªnt_seqè¿›è¡Œæˆªå–ï¼Œå¹¶encodeæˆintegerï¼Œç„¶åŽä¿å­˜\n",
    "            num_steps = len(one_ast) // time_steps # å°†æ¯ä¸ªnt seqéƒ½åˆ‡å‰²æˆtime stepsçš„æ•´æ•°å€\n",
    "            if num_steps == 0: # è¯¥astå¤§å°ä¸è¶³time step èˆåŽ»\n",
    "                continue\n",
    "            one_ast = one_ast[:num_steps * time_steps]\n",
    "            nt_int_seq = [(nonTerminalToken2int[n], terminalToken2int.get(t, terminalToken2int['UNK'])) \n",
    "                          for n, t in one_ast]\n",
    "            data_seq.extend(nt_int_seq)\n",
    "        print(len(data_seq))\n",
    "        total_num_nt_pair += len(data_seq)\n",
    "        with open(subset_data_dir+f'int_format/part{index}.json', 'wb') as file:\n",
    "            pickle.dump(data_seq, file)\n",
    "            print(f'part{index} of nt_seq data has been encoded into integer and saved...')\n",
    "    print(f'There are {total_num_nt_pair} of nt_pair in train data set...') # total == 6970900\n",
    "process_nt_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import data_utils\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = 'processed_data/rnn_train_data.p'\n",
    "data_parameter_path = 'processed_data/rnn_train_parameter.p'\n",
    "tensorboard_log_path = 'logs/MultiRNN'\n",
    "\n",
    "train_dir = 'dataset/programs_800'\n",
    "test_dir = 'dataset/programs_200'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "num_epoches = 1\n",
    "show_every_n = 50\n",
    "save_every_n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_tokens(train_flag=True, is_simplify=True):\n",
    "    if train_flag:\n",
    "        token_dir = train_dir\n",
    "    else:\n",
    "        token_dir = test_dir\n",
    "    token_list = []\n",
    "    for f in os.listdir(token_dir):\n",
    "        file_path = os.path.join(token_dir, f)\n",
    "        if os.path.isfile(file_path) and f.endswith('_tokens.json'):\n",
    "            #print(file_path)\n",
    "            token_seq = json.load(open(file_path, encoding='utf-8'))\n",
    "            token_list.extend(token_seq)\n",
    "    string_token_list = []\n",
    "    for token in token_list:\n",
    "        if is_simplify:\n",
    "            data_utils.simplify_token(token)\n",
    "        string_token = data_utils.token_to_string(token)\n",
    "        string_token_list.append(string_token)\n",
    "    token_set = list(set(string_token_list))\n",
    "    #print(string_token_list[:10])\n",
    "    string2int = {c:i for i,c in enumerate(token_set)}\n",
    "    int2string = {i:c for i,c in enumerate(token_set)}\n",
    "    int_token_list = [string2int[c] for c in string_token_list]\n",
    "    #print(int_token_list[:10])\n",
    "    pickle.dump((int_token_list), open(processed_data_path, 'wb'))\n",
    "    pickle.dump((string2int, int2string, token_set), open(data_parameter_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using MultiRNN to pridect token. with LSTM cell\n",
    "'''\n",
    "class LSTM_Model(object):\n",
    "    def __init__(self,\n",
    "                 token_set, time_steps=100,\n",
    "                 batch_size=64,\n",
    "                 num_layers=2,\n",
    "                 n_units=128,\n",
    "                 learning_rate=0.003,\n",
    "                 grad_clip=5,\n",
    "                 keep_prob=0.5,\n",
    "                 num_epoches = 5,\n",
    "                 is_training=True):\n",
    "        \n",
    "        if is_training:\n",
    "            self.time_steps = time_steps\n",
    "            self.batch_size = batch_size\n",
    "        else:\n",
    "            self.time_steps = 1\n",
    "            self.batch_size = 1\n",
    "        \n",
    "        self.token_set =  token_set\n",
    "        self.num_classes = len(self.token_set)\n",
    "        self.num_layers = num_layers\n",
    "        self.n_units = n_units\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_epoches = num_epoches\n",
    "\n",
    "        self.bulid_model()\n",
    "\n",
    "\n",
    "    def get_batch(self, data_seq, n_seq, n_steps):\n",
    "        '''\n",
    "        :param n_seq: ä¸€ä¸ªbatchä¸­åºåˆ—çš„ä¸ªæ•°\n",
    "        :param n_steps: å•ä¸ªåºåˆ—ä¸­åŒ…å«å­—ç¬¦çš„ä¸ªæ•°\n",
    "        '''\n",
    "        data_seq = np.array(data_seq)\n",
    "        batch_size = n_steps * n_seq\n",
    "        n_batches = len(data_seq) // batch_size\n",
    "        data_seq = data_seq[:batch_size * n_batches] #ä»…ä¿ç•™å®Œæ•´çš„batchï¼ŒèˆåŽ»æœ«å°¾\n",
    "        data_seq = data_seq.reshape((n_seq, -1))\n",
    "        for n in range(0, data_seq.shape[1], n_steps):\n",
    "            x = data_seq[:, n:n+n_steps]\n",
    "            y = np.zeros_like(x)\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], x[:,0]\n",
    "            yield x, y\n",
    "\n",
    "    def build_input(self):\n",
    "        input_x = tf.placeholder(tf.int32, [self.batch_size, self.time_steps], name='input_x')\n",
    "        target_y = tf.placeholder(tf.int32, [self.batch_size, self.time_steps], name='target_y')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "        return input_x, target_y, keep_prob\n",
    "\n",
    "    def bulid_lstm(self, keep_prob):\n",
    "        cell_list = []\n",
    "        for i in range(self.num_layers):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(self.n_units, state_is_tuple=True)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "            cell_list.append(cell)\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(cell_list, state_is_tuple=True)\n",
    "        init_state = cells.zero_state(self.batch_size, dtype=tf.float32)\n",
    "\n",
    "        return cells, init_state\n",
    "\n",
    "    def bulid_output(self, lstm_output):\n",
    "        # å°†lstm_outputçš„å½¢çŠ¶ç”±[batch_size, time_steps, n_units] è½¬æ¢ä¸º [batch_size*time_steps, n_units]\n",
    "        seq_output = tf.concat(lstm_output, axis=1)\n",
    "        seq_output = tf.reshape(seq_output, [-1, self.n_units])\n",
    "\n",
    "        with tf.variable_scope('softmax'):\n",
    "            softmax_w = tf.Variable(tf.truncated_normal([self.n_units, self.num_classes], stddev=0.1))\n",
    "            softmax_b = tf.Variable(tf.zeros(self.num_classes))\n",
    "\n",
    "        logits = tf.matmul(seq_output, softmax_w) + softmax_b\n",
    "        softmax_output = tf.nn.softmax(logits=logits, name='softmax_output')\n",
    "        return softmax_output, logits\n",
    "\n",
    "    def bulid_loss(self, logits, targets):\n",
    "        one_hot_y = tf.one_hot(targets, self.num_classes)\n",
    "        one_hot_y = tf.reshape(one_hot_y, logits.get_shape())\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=one_hot_y)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "    def bulid_optimizer(self,loss):\n",
    "        # tvars = tf.trainable_variables()\n",
    "        # grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), self.grad_clip)\n",
    "        # optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        # optimizer = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        gradient_pairs = optimizer.compute_gradients(loss)\n",
    "        clip_gradient_pairs = []\n",
    "        for grad, var in gradient_pairs:\n",
    "            grad = tf.clip_by_value(grad, -2, 2)\n",
    "            clip_gradient_pairs.append((grad, var))\n",
    "        optimizer = optimizer.apply_gradients(clip_gradient_pairs)\n",
    "        return optimizer\n",
    "    \n",
    "    def build_accuracy(self, logits, targets):\n",
    "#         print(logits.get_shape())\n",
    "#         print(targets.get_shape())\n",
    "        sess = tf.Session()\n",
    "        self.show_logits = tf.argmax(logits, axis=1)\n",
    "        show_targets = tf.one_hot(targets, self.num_classes)\n",
    "        show_targets = tf.reshape(show_targets, logits.get_shape())\n",
    "        self.show_targets = tf.argmax(show_targets, axis=1)\n",
    "        self.aaa = tf.equal(self.show_logits, self.show_targets)\n",
    "        accu = tf.cast(self.aaa, tf.float32)\n",
    "        accu = tf.reduce_mean(accu)\n",
    "        return accu\n",
    "        \n",
    "\n",
    "    def bulid_model(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.input_x, self.target_y, self.keep_prob = self.build_input()\n",
    "        self.cell, self.init_state = self.bulid_lstm(self.keep_prob)\n",
    "        one_hot_x = tf.one_hot(self.input_x, self.num_classes)\n",
    "        #print(one_hot_x.get_shape()) # (64, 100, 86)\n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "            self.cell, one_hot_x, initial_state=self.init_state)\n",
    "        #print(1, lstm_outputs.get_shape()) # (64, 100, 128)\n",
    "        self.softmax_output, logits = self.bulid_output(lstm_outputs)\n",
    "        #print(self.softmax_output.get_shape()) # (6400, 86)\n",
    "        #print(logits.get_shape()) #(6400, 86)\n",
    "        self.loss = self.bulid_loss(logits,self.target_y)\n",
    "        self.accuracy = self.build_accuracy(self.softmax_output, self.target_y)\n",
    "        self.optimizer = self.bulid_optimizer(self.loss)\n",
    "\n",
    "\n",
    "    def train(self, data, string2int, int2string):\n",
    "        print('training begin...')\n",
    "        self.string2int = string2int\n",
    "        self.int2string = int2string\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "        keep_prob = 0.5\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            global_step = 0\n",
    "            for epoch in range(self.num_epoches):\n",
    "                new_state = sess.run(self.init_state)\n",
    "                batch_generator = self.get_batch(data, self.batch_size, self.time_steps)\n",
    "                batch_step = 0\n",
    "                start_time = time.time()\n",
    "                for x, y in batch_generator:\n",
    "                    global_step += 1\n",
    "                    batch_step += 1\n",
    "                    feed = {self.input_x:x,\n",
    "                            self.target_y:y,\n",
    "                            self.keep_prob:keep_prob,\n",
    "                            self.init_state:new_state}\n",
    "                    show_accu, show_loss, new_state, _ = sess.run(\n",
    "                        [self.accuracy, self.loss, self.final_state, self.optimizer], feed_dict=feed)\n",
    "                    end_time = time.time()\n",
    "                    if global_step%show_every_n == 0:\n",
    "                        a, b,c = sess.run([self.show_logits, self.show_targets,self.aaa], feed)\n",
    "                        print(a[:10])\n",
    "                        print(b[:10])\n",
    "                    if global_step % show_every_n == 0:\n",
    "                        print('epoch: {}/{}..'.format(epoch+1, self.num_epoches),\n",
    "                              'global_step: {}..'.format(global_step),\n",
    "                              'train_loss: {:.2f}..'.format(show_loss),\n",
    "                              'train_accuracy: {:.2f}..'.format(show_accu),\n",
    "                              'time cost in per_batch: {:.2f}..'.format(end_time-start_time))\n",
    "\n",
    "                    if global_step % save_every_n == 0:\n",
    "                        saver.save(sess, 'checkpoints/epoch{}_batch_step{}'.format(epoch, batch_step))\n",
    "            saver.save(sess, 'checkpoints/last_check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_utils.load_data_with_pickle(processed_data_path)\n",
    "string2int, int2string, token_set = data_utils.load_data_with_pickle(data_parameter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int2string[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LSTM_Model(token_set)\n",
    "model.train(train_data, string2int, int2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(object):\n",
    "    def __init__(self, token_set,string2int, int2string):\n",
    "        self.model = LSTM_Model(token_set, is_training=False)\n",
    "        self.string2int = string2int\n",
    "        self.int2string = int2string\n",
    "        self.last_chackpoints = tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    # query test\n",
    "    def query_test(self, prefix, suffix):\n",
    "        '''\n",
    "        Input: all tokens before the hole token(prefix) and all tokens after the hole token,\n",
    "        ML model will predict the most probable token in the hole\n",
    "        '''\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, self.last_chackpoints)\n",
    "            new_state = sess.run(self.model.init_state)\n",
    "            prediction = None\n",
    "            for i,token in enumerate(prefix):\n",
    "                x = np.zeros((1, 1), dtype=np.int32)\n",
    "                x[0,0] = token\n",
    "                feed = {self.model.input_x:x,\n",
    "                        self.model.keep_prob:1.,\n",
    "                        self.model.init_state:new_state}\n",
    "                prediction, new_state = sess.run(\n",
    "                    [self.model.softmax_output, self.model.final_state], feed_dict=feed)\n",
    "        prediction = self.int2string[np.argmax(prediction)]\n",
    "        return prediction\n",
    "\n",
    "    def test(self, query_test_data):\n",
    "        correct = 0.0\n",
    "        correct_token_list = []\n",
    "        incorrect_token_list = []\n",
    "        for token_sequence in query_test_data:\n",
    "            prefix, expection, suffix = data_utils.create_hole(token_sequence)\n",
    "            prefix = self.token_to_int(prefix)\n",
    "            prediction = self.query_test(prefix, suffix)\n",
    "            prediction = data_utils.string_to_token(prediction)\n",
    "            if data_utils.token_equals([prediction], expection):\n",
    "                correct += 1\n",
    "                correct_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "            else:\n",
    "                incorrect_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "        accuracy = correct / len(query_test_data)\n",
    "        return accuracy\n",
    "    \n",
    "    def token_to_int(self, token_seq):\n",
    "        int_token_seq = []\n",
    "        for token in token_seq:\n",
    "            int_token = self.string2int[data_utils.token_to_string(token)]\n",
    "            int_token_seq.append(int_token)\n",
    "        return int_token_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_utils.load_data_with_file(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = TestModel(token_set, string2int, int2string)\n",
    "accuracy = test_model.test(test_data)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import data_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "ä½¿ç”¨TensorFlowè‡ªå¸¦çš„layersæž„å»ºåŸºæœ¬çš„ç¥žç»ç½‘ç»œå¯¹tokenè¿›è¡Œé¢„æµ‹ï¼Œ\n",
    "å¯ä»¥å£°æ˜Žä½¿ç”¨å¤šå°‘ä¸ªcontext tokens è¿›è¡Œé¢„æµ‹\n",
    "\n",
    "å¤šä¸ªprevious tokenè¾“å…¥ç¥žç»ç½‘ç»œçš„æ–¹æ³•æœ‰ä¸¤ç§æƒ³æ³•ï¼š\n",
    "1. å°†æ¯ä¸ªtokençš„representation vectorç›¸è¿žï¼Œåˆæˆä¸€ä¸ªå¤§çš„vectorè¾“å…¥åˆ°ç¥žç»ç½‘ç»œï¼Œ\n",
    "    æ‰€ä»¥è¯´ç¥žç»ç½‘ç»œçš„è¾“å…¥å±‚å¤§å°åº”ä¸ºï¼šæ¯ä¸ªtoken vector length * number of previous token\n",
    "2. åº”ä¸ºç›®å‰è¡¨ç¤ºæ¯ä¸ªtoken ä½¿ç”¨çš„æ–¹æ³•ä¸ºone hot encodingï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹æ¯ä¸ªtokenéƒ½æ˜¯æœ‰ä¸”ä»…æœ‰ä¸€ä½ä¸º1ï¼Œå…¶ä½™ä½ä¸º0ï¼Œ\n",
    "    æ‰€ä»¥å¯ä»¥è€ƒè™‘ç›´æŽ¥å°†æ‰€æœ‰çš„previous tokenç›¸åŠ ï¼Œè¿™æ ·åšçš„å¥½å¤„æ˜¯NNè¾“å…¥å±‚å¤§å°æ°¸è¿œç­‰äºŽvector lengthã€‚ç¼ºç‚¹æ˜¯æ²¡æœ‰ç†è®ºä¾æ®ï¼Œä¸çŸ¥é“æ•ˆæžœæ˜¯å¦ä¼šæ›´å¥½\n",
    "\n",
    "\n",
    "1. concatenate the representations of previous tokens to a huge vector representation\n",
    "2. add the representations of previous tokens together\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "x_train_data_path = 'processed_data/x_train_data.p'\n",
    "y_train_data_path = 'processed_data/y_train_data.p'\n",
    "train_data_parameter = 'processed_data/x_y_parameter.p'\n",
    "query_dir = 'dataset/programs_200/'\n",
    "\n",
    "tensorboard_data_path = './logs/MultiContext/5_previous'\n",
    "\n",
    "epoch_num = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.002\n",
    "context_size = 5\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code_Completion_Model:\n",
    "\n",
    "    def __init__(self, x_data, y_data, token_set, string2int, int2string, add_or_concat='add'):\n",
    "        batch_num = len(x_data) // batch_size\n",
    "        x_data, y_data = np.array(x_data[:batch_num * batch_size]), np.array(y_data[:batch_num * batch_size])\n",
    "        if add_or_concat == 'add':\n",
    "            temp_x, temp_y = self.reshape_with_add(x_data, y_data)\n",
    "        if add_or_concat == 'concat':\n",
    "            temp_x, temp_y = self.reshape_with_concat(x_data, y_data)\n",
    "        self.x_data, self.valid_x, self.y_data, self.valid_y = \\\n",
    "            train_test_split(temp_x, temp_y, train_size=0.9)\n",
    "        self.data_size = len(self.x_data)\n",
    "        self.index_to_string = int2string\n",
    "        self.string_to_index = string2int\n",
    "        self.tokens_set = token_set\n",
    "        self.tokens_size = len(token_set)\n",
    "\n",
    "    def reshape_with_concat(self, x_data, y_data):\n",
    "        reshape_data = []\n",
    "        reshape_label = []\n",
    "        for i in range(len(x_data)):\n",
    "            if i >= context_size-1:\n",
    "                temp_list = []\n",
    "                for x in range(context_size):\n",
    "                    temp_list.extend(x_data[i-x])\n",
    "                reshape_data.append(temp_list)\n",
    "                reshape_label.append(y_data[i])\n",
    "        return reshape_data, reshape_label\n",
    "        \n",
    "    def reshape_with_add(self, x_data, y_data):\n",
    "        x = []\n",
    "        y = []\n",
    "        for index, token in enumerate(x_data):\n",
    "            if index >= context_size - 1:\n",
    "                tempTokens = np.sum(x_data[index - context_size + 1:index + 1, :], axis=0)\n",
    "                x.append(tempTokens)\n",
    "                y.append(y_data[index])\n",
    "        return x, y;\n",
    "\n",
    "    # neural network functions\n",
    "    def create_NN(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.input_x = tf.placeholder(dtype=tf.float32, shape=[None, self.tokens_size], name='input_x')\n",
    "        self.output_y = tf.placeholder(dtype=tf.float32, shape=[None, self.tokens_size], name='output_y')\n",
    "        weights = {'h1': tf.Variable(tf.truncated_normal(shape=[self.tokens_size, hidden_size])),\n",
    "                   'h2': tf.Variable(tf.truncated_normal(shape=[hidden_size, hidden_size])),\n",
    "                   'h3': tf.Variable(tf.truncated_normal(shape=[hidden_size, hidden_size])),\n",
    "                   'output': tf.Variable(tf.truncated_normal(shape=[hidden_size, self.tokens_size]))}\n",
    "        biases = {'h1': tf.Variable(tf.constant(0.1, shape=[hidden_size], dtype=tf.float32)),\n",
    "                  'h2': tf.Variable(tf.constant(0.1, shape=[hidden_size], dtype=tf.float32)),\n",
    "                  'h3': tf.Variable(tf.constant(0.1, shape=[hidden_size], dtype=tf.float32)),\n",
    "                  'output': tf.Variable(tf.constant(0.1, shape=[self.tokens_size], dtype=tf.float32))}\n",
    "\n",
    "        h1_layer = tf.matmul(self.input_x, weights['h1']) + biases['h1']\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        h2_layer = tf.matmul(h1_layer, weights['h2']) + biases['h2']\n",
    "        h2_layer = tf.nn.relu(h2_layer)\n",
    "        h3_layer = tf.matmul(h2_layer, weights['h3']) + biases['h3']\n",
    "        h3_layer = tf.nn.relu(h3_layer)\n",
    "        output_layer = tf.matmul(h3_layer, weights['output']) + biases['output']\n",
    "        self.prediction = tf.argmax(output_layer, 1)\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=self.output_y)\n",
    "        self.loss = tf.reduce_mean(loss)\n",
    "        self.optimizer_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "        equal = tf.equal(tf.argmax(output_layer, 1), tf.argmax(self.output_y, 1))\n",
    "        accuracy = tf.cast(equal, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(accuracy)\n",
    "        \n",
    "#         self.valid_loss = tf.reduce_mean(loss)\n",
    "#         self.valid_accuracy = tf.reduce_mean(accuracy)\n",
    "\n",
    "        tf.summary.histogram('weight1', weights['h1'])\n",
    "        tf.summary.histogram('weight2', weights['h2'])\n",
    "        tf.summary.histogram('output_weight', weights['output'])\n",
    "        tf.summary.histogram('bias1', biases['h1'])\n",
    "        tf.summary.histogram('bias2', biases['h2'])\n",
    "        tf.summary.histogram('output_bias', biases['output'])\n",
    "        tf.summary.scalar('train_loss', self.loss)\n",
    "        tf.summary.scalar('train_accuracy', self.accuracy)\n",
    "         \n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "    def get_batch(self):\n",
    "        for i in range(0, len(self.x_data), batch_size):\n",
    "            batch_x = self.x_data[i:i + batch_size];\n",
    "            batch_y = self.y_data[i:i + batch_size];\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "    def train(self):\n",
    "        self.create_NN()\n",
    "        self.sess = tf.Session()\n",
    "        valid_accu_list = np.zeros(10, dtype=np.float32)\n",
    "        train_accu_list = np.zeros(10, dtype=np.float32)\n",
    "        valid_list_index = 0\n",
    "        train_list_index = 0\n",
    "        writer = tf.summary.FileWriter(tensorboard_data_path, self.sess.graph)\n",
    "        time_begin = time.time()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epoch_num):\n",
    "          #  self.x_data, self.y_data = shuffle(self.x_data, self.y_data)\n",
    "            batch_generator = self.get_batch()\n",
    "            for i in range(0, len(self.x_data), batch_size):\n",
    "                batch_x, batch_y = next(batch_generator)\n",
    "                feed = {self.input_x: batch_x, self.output_y: batch_y}\n",
    "                _, summary_str = self.sess.run([self.optimizer_op, self.merged], feed_dict=feed)\n",
    "                writer.add_summary(summary_str, epoch*self.data_size + i)\n",
    "                writer.flush()\n",
    "                if (i // batch_size) % 2000 == 0:\n",
    "                    print('epoch: %d, step: %d'%(epoch, i))\n",
    "                    train_loss, train_accu = self.sess.run([self.loss, self.accuracy], feed_dict=feed)\n",
    "                    train_accu_list[train_list_index % 10] = train_accu\n",
    "                    print('train loss: %.2f, train accuracy:%.3f' % (train_loss, train_accu))\n",
    "                    print('average train accuracy: %.4f'%(np.mean(train_accu_list)))\n",
    "                    valid_feed = {self.input_x:self.valid_x, self.output_y:self.valid_y}\n",
    "                    valid_loss, valid_acc = self.sess.run([self.loss, self.accuracy], feed_dict=valid_feed)\n",
    "                    valid_accu_list[valid_list_index % 10] = valid_acc\n",
    "                    print('valid loss: %.2f, valid accuracy:%.3f' % (valid_loss, valid_acc))\n",
    "                    print('average valid accuracy: %.4f'%(np.mean(valid_accu_list)))\n",
    "        time_end = time.time()\n",
    "        print('training time cost: %.3f s' % (time_end - time_begin))\n",
    "\n",
    "    # query test\n",
    "    def query_test(self, prefix, suffix):\n",
    "        '''\n",
    "        Input: all tokens before the hole token(prefix) and all tokens after the hole token,\n",
    "        ML model will predict the most probable token in the hole. In this function, use only one token before hole token to predict\n",
    "        '''\n",
    "        previous_token_list = prefix[-context_size:]\n",
    "        context_representation = np.zeros(self.tokens_size)\n",
    "\n",
    "        for token in previous_token_list:\n",
    "            prev_token_string = data_utils.token_to_string(token)\n",
    "            pre_token_x = data_utils.one_hot_encoding(prev_token_string, self.string_to_index)\n",
    "            context_representation += np.array(pre_token_x)\n",
    "\n",
    "        feed = {self.input_x: [context_representation]}\n",
    "        prediction = self.sess.run(self.prediction, feed)[0]\n",
    "        best_string = self.index_to_string[prediction]\n",
    "        best_token = data_utils.string_to_token(best_string)\n",
    "        return [best_token]\n",
    "\n",
    "    # test model\n",
    "    def test_model(self, query_test_data):\n",
    "        correct = 0.0\n",
    "        correct_token_list = []\n",
    "        incorrect_token_list = []\n",
    "        for token_sequence in query_test_data:\n",
    "            prefix, expection, suffix = data_utils.create_hole(token_sequence)\n",
    "            prediction = self.query_test(prefix, suffix)[0]\n",
    "            if data_utils.token_equals([prediction], expection):\n",
    "                correct += 1\n",
    "                correct_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "            else:\n",
    "                incorrect_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "        accuracy = correct / len(query_test_data)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data_path = 'processed_data/x_train_data.p'\n",
    "y_train_data_path = 'processed_data/y_train_data.p'\n",
    "train_data_parameter = 'processed_data/x_y_parameter.p'\n",
    "x_data = data_utils.load_data_with_pickle(x_train_data_path)\n",
    "y_data = data_utils.load_data_with_pickle(y_train_data_path)\n",
    "token_set, string2int, int2string = data_utils.load_data_with_pickle(train_data_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model train\n",
    "model = Code_Completion_Model(x_data, y_data, token_set, string2int, int2string)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "query_test_data = data_utils.load_data_with_file(query_dir)\n",
    "accuracy = model.test_model(query_test_data)\n",
    "print('query test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "import data_utils\n",
    "string_processed_data_path = 'processed_data/str_train_data.p'\n",
    "\n",
    "class Markov_Model(object):\n",
    "\n",
    "    def __init__(self, max_length=1, is_most=False):\n",
    "        self.markov_table = {}\n",
    "        self.max_length = 1\n",
    "        self.is_most = False\n",
    "\n",
    "    def create_model(self, token_list, max_depth=1, is_most=False):\n",
    "        '''\n",
    "        create a markov model with the depth from 1 to max_depth\n",
    "        {\n",
    "            depth1:{\n",
    "                key1:[value1, value2 ..]\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        self.is_most = is_most\n",
    "        self.max_length = max_depth\n",
    "        for depth in range(1, max_depth+1):\n",
    "            temp_table = {}\n",
    "            for index in range(depth, len(token_list)):\n",
    "                words = tuple(token_list[index-depth:index])\n",
    "                if words in temp_table.keys():\n",
    "                    temp_table[words].append(token_list[index])\n",
    "                else:\n",
    "                    temp_table.setdefault(words, []).append(token_list[index])\n",
    "            if is_most:\n",
    "                for key,value in temp_table.items():\n",
    "                    temp = Counter(value).most_common(1)[0][0]\n",
    "                    temp_table[key] = temp\n",
    "                self.markov_table[depth] = temp_table\n",
    "            else:\n",
    "                self.markov_table[depth] = temp_table\n",
    "        return self.markov_table\n",
    "\n",
    "    def test_model(self, test_token_lists, depth=1):\n",
    "        correct = 0\n",
    "        correct_token_list = []\n",
    "        incorrect_token_list = []\n",
    "\n",
    "        for tokens in test_token_lists:\n",
    "            prefix, expection, suffix = data_utils.create_hole(tokens)\n",
    "            prediction = self.query_test(prefix, depth=depth)\n",
    "            if prediction['type']==expection[0]['type'] and prediction['value'] == expection[0]['value']:\n",
    "                correct += 1\n",
    "                correct_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "            else:\n",
    "                incorrect_token_list.append({'expection': expection, 'prediction': prediction})\n",
    "        accuracy = correct / len(test_token_lists)\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def query_test(self, pre_tokens, depth=1):\n",
    "        while(depth>self.max_length):\n",
    "            depth -= 1\n",
    "        used_tokens = pre_tokens[-depth:]\n",
    "        proceed_tokens = []\n",
    "        for token in used_tokens:\n",
    "            proceed_tokens.append(data_utils.token_to_string(token))\n",
    "        proceed_tokens = tuple(proceed_tokens)\n",
    "        while proceed_tokens not in self.markov_table[depth].keys() and depth > 1:\n",
    "            depth -= 1\n",
    "            proceed_tokens = tuple(proceed_tokens[-depth:])\n",
    "\n",
    "        if self.is_most:\n",
    "            candidate = self.markov_table[depth][proceed_tokens]\n",
    "        else:\n",
    "            candidate_list = self.markov_table[depth][proceed_tokens]\n",
    "            random_index = random.randint(0, len(candidate_list)-1)\n",
    "            candidate = candidate_list[random_index]\n",
    "        prediction = data_utils.string_to_token(candidate)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_token_list = data_utils.load_data_with_pickle(string_processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = Markov_Model()\n",
    "markov_table = markov_model.create_model(string_token_list, max_depth=6, is_most=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(markov_table[1].keys())\n",
    "#print(markov_table[1][('Keyword~$$~var',)])\n",
    "#print(markov_table[2].keys())\n",
    "test_token_sequences = data_utils.load_data_with_file()\n",
    "accuracy = 0.0\n",
    "test_epoch = 10\n",
    "for i in range(test_epoch):\n",
    "    accuracy += markov_model.test_model(test_token_sequences, depth=6)\n",
    "accuracy /= test_epoch\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.arange(40).reshape((8,5))\n",
    "label = np.arange(8)\n",
    "print(data)\n",
    "print(label)\n",
    "size = 3\n",
    "reshape_data = []\n",
    "reshape_label = []\n",
    "for i in range(len(data)):\n",
    "    if i >= size-1:\n",
    "        temp_list = []\n",
    "        for x in range(size):\n",
    "            temp_list.extend(data[i-x])\n",
    "        reshape_data.append(temp_list)\n",
    "        reshape_label.append(label[i])\n",
    "        \n",
    "print(reshape_data)\n",
    "print(reshape_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
